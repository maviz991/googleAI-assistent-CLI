# googleAI-assistent-CLI
Gemini assitente via API no terminal

# Criando um Assistente Gemini na Linha de Comando (CLI)

Este guia esquematiza os passos para criar um comando global `gemini` no seu terminal Linux (Debian/WSL) para interagir com a API do Google Gemini.

#### Pr√©-requisitos
- Python 3 e `pip3` instalados.
- Uma API Key do Google AI Studio.
- Ambiente Linux (Usei WSL com Debian ou similar).

#### Passo 1: Configura√ß√£o da Chave de API
Crie um arquivo `.env` no seu diret√≥rio home para armazenar a chave de forma segura.

```bash
# Substitua SUA_API_KEY_AQUI pela sua chave real
echo 'GOOGLE_API_KEY="SUA_API_KEY_AQUI"' > ~/.env
```
Crie sua Google AI Studio key aqui ['Google IA Studio API Key'](https://aistudio.google.com/app/apikey)
#### Passo 2: O Script Python (`gemini-chat.py`)
Crie o arquivo [`gemini-chat.py`](/gemini-chat.py) (em uma pasta de projetos) com o c√≥digo Python final que se conecta √† API, l√™ argumentos e gerencia a conversa. *Use o c√≥digo completo da resposta anterior.*

#### Passo 3: Instala√ß√£o das Depend√™ncias Globais
Para que o comando funcione de qualquer lugar, as bibliotecas precisam ser instaladas no ambiente Python global do sistema.

```bash
pip3 install google-generativeai python-dotenv
```

#### Passo 4: Transformando o Script em Comando Global

1.  **Dar Permiss√£o de Execu√ß√£o:**
    ```bash
    # Navegue at√© a pasta onde salvou o script
    chmod +x gemini-chat.py
    ```

2.  **Garantir que o Diret√≥rio de Bin√°rios Locais est√° no PATH:**
    O diret√≥rio `~/.local/bin` √© o local padr√£o para scripts de usu√°rio.
    ```bash
    # Adiciona a linha ao seu .bashrc se ela n√£o existir
    echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
    # Recarrega o terminal para aplicar a mudan√ßa
    source ~/.bashrc
    ```

3.  **Criar o Link Simb√≥lico (o comando `gemini`):**
    Isso cria um "atalho" chamado `gemini` dentro da pasta que o sistema usa para encontrar comandos.
    ```bash
    # Execute este comando de dentro da pasta onde est√° o gemini-chat.py
    ln -s "$(pwd)/gemini-chat.py" ~/.local/bin/gemini
    ```

#### Passo 5: Solu√ß√£o de Problemas Comuns

- **Erro `env: ‚Äòpython3\r‚Äô: No such file or directory`**:
  - **Causa**: Quebras de linha no formato Windows (CRLF).
  - **Solu√ß√£o**: `sudo apt install dos2unix && dos2unix gemini-chat.py`

- **Erro `ModuleNotFoundError: No module named 'google'`**:
  - **Causa**: Bibliotecas instaladas em um `venv` e n√£o no ambiente global.
  - **Solu√ß√£o**: `pip3 install google-generativeai python-dotenv` (sem `venv` ativo).

- **Resposta da IA "N√£o consigo ler arquivos locais"**:
  - **Causa**: O prompt est√° acionando o "reflexo de seguran√ßa" da IA.
  - **Solu√ß√£o**: Ajustar o prompt para ser mais direto, tratando o conte√∫do como "contexto" ou "texto", n√£o como um "arquivo". (O script final j√° faz isso).

---
### Como Usar seu Novo Comando

#### Modo de Comando √önico (com flags)

- **Pergunta R√°pida:**
  ```bash
  gemini "Qual a capital da Mong√≥lia?"
  ```
- **Resumir um Arquivo:**
  ```bash
  gemini -f ./meu_script.js
  ```
- **Fazer uma Pergunta sobre um Arquivo:**
  ```bash
  gemini -f ./relatorio.txt "quais foram os principais pontos levantados no terceiro trimestre?"
  ```
- **Salvar a Sa√≠da em um Arquivo:**
  ```bash
  gemini -f ./codigo.py "documente esta fun√ß√£o em markdown" -o documentacao.md
  ```

#### Modo Conversacional (Interativo)

- **Iniciar uma Conversa:**
  ```bash
  gemini
  ```
- **Comandos Especiais (Dentro do Chat):**
  - **`/load <arquivo> <pergunta>`**: Faz uma pergunta sobre um arquivo e adiciona a an√°lise ao hist√≥rico da conversa, permitindo perguntas de acompanhamento.
    ```
    üßë Voc√™: /load ./meu_codigo.py qual o objetivo principal deste script?
    ```
  - **`/save <arquivo>`**: Salva o hist√≥rico completo da conversa atual em um arquivo.
    ```
    üßë Voc√™: /save minha_conversa.md
    ```
  - **`/help`**: Mostra a lista de comandos dispon√≠veis.
  - **`/exit`, `/quit`, `/sair`**: Encerra a sess√£o de chat.

---

### Fluxograma
- **Fazer uma Pergunta sobre um Arquivo:**
  ```bash
  gemini quais foram os principais pontos levantados no terceiro trimestre? -f ./relatorio.txt"
  ```

```mermaid
flowchart TD
    A[In√≠cio: Comando 'gemini' executado] --> B{Flags -f ou -o usadas?}

    B -- Sim --> C1
    B -- N√£o --> D1

    subgraph ModoComandoUnico [Modo de Comando √önico]
        direction LR
        C1[L√™ arquivo se -f] --> C2[Monta prompt robusto]
        C2 --> C3["Chama model.generate_content()"]
        C3 --> C4{Flag -o usada?}
        C4 -- Sim --> C5[Salva resposta em arquivo]
        C4 -- N√£o --> C6[Exibe resposta no terminal]
    end

    subgraph ModoConversacional [Modo Conversacional]
        D1[Inicia loop de chat] --> D2{Input come√ßa com '/'}
        
        D2 -- N√£o --> D3{Contexto de arquivo carregado?}
        D3 -- Sim --> D4[Envia prompt + Objeto do Arquivo]
        D4 --> D5[Limpa contexto do arquivo]
        D5 --> D6[Exibe resposta da IA]
        D6 --> D1
        D3 -- N√£o --> D7[Envia somente o prompt de texto]
        D7 --> D6

        D2 -- Sim --> D8{Qual comando?}
        D8 -- /load --> D9[Faz Upload do Arquivo via API File]
        D9 --> D10[Armazena objeto do arquivo em contexto]
        D10 --> D1
        
        D8 -- /save --> D11[Salva hist√≥rico]
        D11 --> D1
        
        D8 -- /help --> D12[Mostra ajuda]
        D12 --> D1
        
        D8 -- /exit --> Fim([Fim do Programa])
    end

    C5 --> Fim
    C6 --> Fim

